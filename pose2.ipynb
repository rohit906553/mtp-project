{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a161993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing train set...\n",
      "ðŸ“· Found 9952 images in: C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9952/9952 [00:27<00:00, 360.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing test set...\n",
      "ðŸ“· Found 10793 images in: C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10793/10793 [00:34<00:00, 314.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done drawing all bounding boxes and saving images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- CONFIG --------\n",
    "DATASET = {\n",
    "    'train': {\n",
    "        'img_dir': 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/images',\n",
    "        'label_dir': 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/labels',\n",
    "        'output_dir': 'train_output'\n",
    "    },\n",
    "    'test': {\n",
    "        'img_dir': 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/images',\n",
    "        'label_dir': 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/labels',\n",
    "        'output_dir': 'test_output'\n",
    "    }\n",
    "}\n",
    "\n",
    "# YOLO class names (edit this according to your dataset)\n",
    "CLASS_NAMES = {\n",
    "    0: \"spacecraft\"\n",
    "    # Add more classes if needed\n",
    "}\n",
    "\n",
    "def draw_boxes(image_path, label_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"âŒ Failed to load image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"âš ï¸ Label file not found for image: {image_path}\")\n",
    "        return img  # No label file, return original image\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"âš ï¸ Malformed line in label file: {label_path}\")\n",
    "                continue\n",
    "            cls_id, x_c, y_c, box_w, box_h = map(float, parts)\n",
    "\n",
    "            # Convert to pixel coordinates\n",
    "            x_c, y_c, box_w, box_h = x_c * w, y_c * h, box_w * w, box_h * h\n",
    "            x1 = int(x_c - box_w / 2)\n",
    "            y1 = int(y_c - box_h / 2)\n",
    "            x2 = int(x_c + box_w / 2)\n",
    "            y2 = int(y_c + box_h / 2)\n",
    "\n",
    "            label = CLASS_NAMES.get(int(cls_id), str(int(cls_id)))\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "# -------- PROCESS --------\n",
    "for split in DATASET:\n",
    "    img_dir = DATASET[split]['img_dir']\n",
    "    label_dir = DATASET[split]['label_dir']\n",
    "    output_dir = DATASET[split]['output_dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    print(f\"ðŸ“‚ Processing {split} set...\")\n",
    "    print(f\"ðŸ“· Found {len(image_files)} images in: {img_dir}\")\n",
    "\n",
    "    for img_file in tqdm(image_files, desc=f\"Processing {split} set\"):\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        result_img = draw_boxes(img_path, label_path)\n",
    "        if result_img is None:\n",
    "            continue\n",
    "\n",
    "        output_path = os.path.join(output_dir, img_file)\n",
    "        success = cv2.imwrite(output_path, result_img)\n",
    "        if not success:\n",
    "            print(f\"âŒ Failed to save output image: {output_path}\")\n",
    "\n",
    "print(\"âœ… Done drawing all bounding boxes and saving images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ce307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.7\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32213fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "image_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/images\"\n",
    "label_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/labels\"\n",
    "output_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/labels_with_keypoints\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label_file in os.listdir(label_dir):\n",
    "    if not label_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    image_name = label_file.replace(\".txt\", \".jpg\")\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(os.path.join(output_dir, label_file), \"w\") as out:\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "\n",
    "            cls, x_center, y_center, w, h = map(float, parts[:5])\n",
    "            \n",
    "            # Convert from normalized to pixel values\n",
    "            x_c = x_center * img_w\n",
    "            y_c = y_center * img_h\n",
    "            bw = w * img_w\n",
    "            bh = h * img_h\n",
    "\n",
    "            # Bounding box corners\n",
    "            x_min = x_c - bw / 2\n",
    "            x_max = x_c + bw / 2\n",
    "            y_min = y_c - bh / 2\n",
    "            y_max = y_c + bh / 2\n",
    "\n",
    "            # Keypoints (in pixels)\n",
    "            keypoints = [\n",
    "                (x_min, y_min),  # Top-left\n",
    "                (x_max, y_min),  # Top-right\n",
    "                (x_min, y_max),  # Bottom-left\n",
    "                (x_max, y_max),  # Bottom-right\n",
    "                (x_c, y_c)       # Center\n",
    "            ]\n",
    "\n",
    "            # Write bbox line\n",
    "            out.write(f\"{cls} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "            \n",
    "            # Write keypoints in normalized format\n",
    "            for idx, (kp_x, kp_y) in enumerate(keypoints):\n",
    "                kp_x_norm = kp_x / img_w\n",
    "                kp_y_norm = kp_y / img_h\n",
    "                out.write(f\"{kp_x_norm:.6f} {kp_y_norm:.6f} {float(idx):.1f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc42f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "image_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/images\"\n",
    "label_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/labels\"\n",
    "output_dir = \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/labels_with_keypoints\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label_file in os.listdir(label_dir):\n",
    "    if not label_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    image_name = label_file.replace(\".txt\", \".jpg\")\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(os.path.join(output_dir, label_file), \"w\") as out:\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "\n",
    "            cls, x_center, y_center, w, h = map(float, parts[:5])\n",
    "            \n",
    "            # Convert from normalized to pixel values\n",
    "            x_c = x_center * img_w\n",
    "            y_c = y_center * img_h\n",
    "            bw = w * img_w\n",
    "            bh = h * img_h\n",
    "\n",
    "            # Bounding box corners\n",
    "            x_min = x_c - bw / 2\n",
    "            x_max = x_c + bw / 2\n",
    "            y_min = y_c - bh / 2\n",
    "            y_max = y_c + bh / 2\n",
    "\n",
    "            # Keypoints (in pixels)\n",
    "            keypoints = [\n",
    "                (x_min, y_min),  # Top-left\n",
    "                (x_max, y_min),  # Top-right\n",
    "                (x_min, y_max),  # Bottom-left\n",
    "                (x_max, y_max),  # Bottom-right\n",
    "                (x_c, y_c)       # Center\n",
    "            ]\n",
    "\n",
    "            # Write bbox line\n",
    "            out.write(f\"{cls} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "            \n",
    "            # Write keypoints in normalized format\n",
    "            for idx, (kp_x, kp_y) in enumerate(keypoints):\n",
    "                kp_x_norm = kp_x / img_w\n",
    "                kp_y_norm = kp_y / img_h\n",
    "                out.write(f\"{kp_x_norm:.6f} {kp_y_norm:.6f} {float(idx):.1f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0518b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def draw_bbox_and_keypoints(image_path, label_path, save_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "\n",
    "    if not lines or len(lines) < 6:\n",
    "        print(f\"Skipping: {image_path} due to insufficient keypoints.\")\n",
    "        return\n",
    "\n",
    "    # === BBOX ===\n",
    "    class_id, cx, cy, bw, bh = map(float, lines[0].split())\n",
    "    x1 = int((cx - bw / 2) * w)\n",
    "    y1 = int((cy - bh / 2) * h)\n",
    "    x2 = int((cx + bw / 2) * w)\n",
    "    y2 = int((cy + bh / 2) * h)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # === KEYPOINTS ===\n",
    "    for line in lines[1:6]:  # 5 keypoints\n",
    "        x_norm, y_norm, idx = map(float, line.split())\n",
    "        x = int(x_norm * w)\n",
    "        y = int(y_norm * h)\n",
    "        cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.putText(img, str(int(idx)), (x+5, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "# === CONFIG ===\n",
    "def process_dataset(img_dir, label_dir, save_dir):\n",
    "    for file in os.listdir(img_dir):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            img_path = os.path.join(img_dir, file)\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(file)[0] + \".txt\")\n",
    "            save_path = os.path.join(save_dir, file)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                draw_bbox_and_keypoints(img_path, label_path, save_path)\n",
    "            else:\n",
    "                print(f\"Label not found for: {file}\")\n",
    "\n",
    "# === PATHS ===\n",
    "TRAIN_IMG_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/images'\n",
    "TRAIN_LABEL_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/labels_with_keypoints'\n",
    "TRAIN_SAVE_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_visualised'\n",
    "\n",
    "TEST_IMG_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/images'\n",
    "TEST_LABEL_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/labels_with_keypoints'\n",
    "TEST_SAVE_DIR = 'C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_visualised'\n",
    "\n",
    "# === RUN ===\n",
    "process_dataset(TRAIN_IMG_DIR, TRAIN_LABEL_DIR, TRAIN_SAVE_DIR)\n",
    "process_dataset(TEST_IMG_DIR, TEST_LABEL_DIR, TEST_SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45228f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9952/9952 [00:07<00:00, 1420.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 9952 poses to C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10793/10793 [00:07<00:00, 1427.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10793 poses to C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Camera configuration\n",
    "IMG_WIDTH = 2448\n",
    "IMG_HEIGHT = 2048\n",
    "SENSOR_WIDTH_MM = 8.4456\n",
    "SENSOR_HEIGHT_MM = 7.0656\n",
    "FOCAL_LENGTH_MM = 12\n",
    "\n",
    "FOCAL_LENGTH_PIX_X = FOCAL_LENGTH_MM / SENSOR_WIDTH_MM * IMG_WIDTH\n",
    "FOCAL_LENGTH_PIX_Y = FOCAL_LENGTH_MM / SENSOR_HEIGHT_MM * IMG_HEIGHT\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [FOCAL_LENGTH_PIX_X, 0, IMG_WIDTH / 2],\n",
    "    [0, FOCAL_LENGTH_PIX_Y, IMG_HEIGHT / 2],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "DIST_COEFFS = np.zeros((4, 1))\n",
    "\n",
    "def parse_label(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    bbox = list(map(float, lines[0].strip().split()[1:]))  # skip class_id\n",
    "    keypoints = []\n",
    "    for kp_line in lines[1:]:\n",
    "        parts = kp_line.strip().split()\n",
    "        if len(parts) == 3:\n",
    "            x, y = float(parts[0]), float(parts[1])\n",
    "            keypoints.append([x * IMG_WIDTH, y * IMG_HEIGHT])\n",
    "    return bbox, np.array(keypoints, dtype=np.float32)\n",
    "\n",
    "def get_3d_keypoints(n):\n",
    "    \"\"\"Assume a square flat target (or known depth). Customize this if needed.\"\"\"\n",
    "    size = 0.1  # in meters\n",
    "    return np.array([[i % 2 * size, i // 2 * size, 0] for i in range(n)], dtype=np.float32)\n",
    "\n",
    "def estimate_pose(image_path, label_path):\n",
    "    bbox, img_keypoints = parse_label(label_path)\n",
    "    if len(img_keypoints) < 4:\n",
    "        return None\n",
    "\n",
    "    obj_keypoints = get_3d_keypoints(len(img_keypoints))\n",
    "    success, rvec, tvec = cv2.solvePnP(obj_keypoints, img_keypoints, CAMERA_MATRIX, DIST_COEFFS)\n",
    "    if not success:\n",
    "        return None\n",
    "\n",
    "    rot_mat, _ = cv2.Rodrigues(rvec)\n",
    "    r = R.from_matrix(rot_mat)\n",
    "    quat = r.as_quat()  # x, y, z, w\n",
    "    euler = r.as_euler('xyz', degrees=True)  # roll, pitch, yaw\n",
    "\n",
    "    return [os.path.basename(image_path), *tvec.flatten(), *euler, *quat]\n",
    "\n",
    "def process_dataset(img_dir, label_dir, save_csv):\n",
    "    results = []\n",
    "    image_paths = sorted(glob(os.path.join(img_dir, '*.jpg')))\n",
    "\n",
    "    for img_path in tqdm(image_paths):\n",
    "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(label_dir, f\"{img_name}.txt\")\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        pose = estimate_pose(img_path, label_path)\n",
    "        if pose:\n",
    "            results.append(pose)\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\n",
    "        \"IMG_NUM\", \"X\", \"Y\", \"Z\", \"ROLL\", \"PITCH\", \"YAW\", \"Q1\", \"Q2\", \"Q3\", \"W\"\n",
    "    ])\n",
    "    df.to_csv(save_csv, index=False)\n",
    "    print(f\"Saved {len(df)} poses to {save_csv}\")\n",
    "\n",
    "# ðŸ§ª PASS YOUR PATHS HERE:\n",
    "process_dataset(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_visualised\", \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/labels_with_keypoints\", \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_results.csv\")\n",
    "process_dataset(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_visualised\", \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/labels_with_keypoints\", \"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d540ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load predicted pose file\n",
    "pred = pd.read_csv(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_results.csv\")\n",
    "\n",
    "# Clean filenames\n",
    "pred[\"IMG_NUM\"] = pred[\"IMG_NUM\"].apply(lambda x: x.split(\"_jpg\")[0] + \".jpg\")\n",
    "\n",
    "# Save cleaned version\n",
    "pred.to_csv(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_results1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d1aacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load predicted pose file\n",
    "pred = pd.read_csv(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_results.csv\")\n",
    "\n",
    "# Clean filenames\n",
    "pred[\"IMG_NUM\"] = pred[\"IMG_NUM\"].apply(lambda x: x.split(\"_jpg\")[0] + \".jpg\")\n",
    "\n",
    "# Save cleaned version\n",
    "pred.to_csv(\"C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_results1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f099fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Metrics:\n",
      "âœ… Accuracy       : 0.9011\n",
      "âœ… F1 Score       : 0.9480\n",
      "\n",
      "ðŸ“ˆ Regression Error Metrics on Total Error:\n",
      "âœ… MSE            : 16997.6785\n",
      "âœ… RMSE           : 130.3751\n",
      "âœ… MAE            : 125.4481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score,auc,\n",
    "    mean_squared_error, mean_absolute_error,\n",
    ")\n",
    "\n",
    "# --- Step 1: Load the Data ---\n",
    "gt = pd.read_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/dataset/train/train_ground_truth.csv')\n",
    "pred = pd.read_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_results1.csv')\n",
    "\n",
    "# Sort by IMG_NUM for alignment\n",
    "gt = gt.sort_values(by='IMG_NUM').reset_index(drop=True)\n",
    "pred = pred.sort_values(by='IMG_NUM').reset_index(drop=True)\n",
    "\n",
    "assert len(gt) == len(pred), \"Mismatch in number of rows between ground truth and predictions\"\n",
    "\n",
    "# --- Step 2: Calculate Errors ---\n",
    "# Translational Error\n",
    "trans_error = np.linalg.norm(gt[['X', 'Y', 'Z']].values - pred[['X', 'Y', 'Z']].values, axis=1)\n",
    "\n",
    "# Rotational Error (Quaternion difference)\n",
    "def quat_error(q1, q2):\n",
    "    dot = np.abs(np.sum(q1 * q2, axis=1))  # absolute dot product\n",
    "    dot = np.clip(dot, -1.0, 1.0)\n",
    "    return 2 * np.arccos(dot) * 180 / np.pi  # degrees\n",
    "\n",
    "q_gt = gt[['Q1', 'Q2', 'Q3', 'W']].values\n",
    "q_pred = pred[['Q1', 'Q2', 'Q3', 'W']].values\n",
    "rot_error = quat_error(q_gt, q_pred)\n",
    "\n",
    "# Total Error\n",
    "total_error = np.sqrt(trans_error**2 + rot_error**2)\n",
    "\n",
    "# --- Step 3: Apply Threshold ---\n",
    "threshold = 170.0  # set your threshold here\n",
    "y_true = np.ones(len(total_error))  # ground truth: always acceptable (1)\n",
    "y_pred = (total_error <= threshold).astype(int)  # 1 = pass, 0 = fail\n",
    "\n",
    "# --- Step 4: Save Everything to CSV ---\n",
    "df_out = pd.DataFrame({\n",
    "    'IMG_NUM': gt['IMG_NUM'],\n",
    "    'Translational_Error': trans_error,\n",
    "    'Rotational_Error': rot_error,\n",
    "    'Total_Error': total_error,\n",
    "    'Pass_or_Fail': y_pred\n",
    "})\n",
    "df_out.to_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/train dataset/train/train_pose_error_with_threshold.csv', index=False)\n",
    "\n",
    "# --- Step 5: Metrics ---\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# --- Step 6: Regression Metrics ---\n",
    "mse = mean_squared_error(np.zeros_like(total_error), total_error)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(np.zeros_like(total_error), total_error)\n",
    "\n",
    "\n",
    "# --- Step 7: Plot Metrics and Save ---\n",
    "# Confusion Matrix\n",
    "\n",
    "\n",
    "# F1 Score Plot\n",
    "plt.figure()\n",
    "plt.bar(['F1 Score'], [f1], color='purple')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('F1 Score')\n",
    "plt.savefig('f1_score.png')\n",
    "plt.close()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure()\n",
    "plt.bar(['Accuracy'], [accuracy], color='green')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.savefig('accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 8: Print Metrics ---\n",
    "print(\"ðŸ“Š Classification Metrics:\")\n",
    "print(f\"âœ… Accuracy       : {accuracy:.4f}\")\n",
    "print(f\"âœ… F1 Score       : {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“ˆ Regression Error Metrics on Total Error:\")\n",
    "print(f\"âœ… MSE            : {mse:.4f}\")\n",
    "print(f\"âœ… RMSE           : {rmse:.4f}\")\n",
    "print(f\"âœ… MAE            : {mae:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71c8aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Metrics:\n",
      "âœ… Accuracy       : 0.9397\n",
      "âœ… F1 Score       : 0.9689\n",
      "\n",
      "ðŸ“ˆ Regression Error Metrics on Total Error:\n",
      "âœ… MSE            : 13310.8558\n",
      "âœ… RMSE           : 115.3727\n",
      "âœ… MAE            : 109.2404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score,auc,\n",
    "    mean_squared_error, mean_absolute_error,\n",
    ")\n",
    "\n",
    "# --- Step 1: Load the Data ---\n",
    "gt = pd.read_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/sequence_a/test_ground_truth.csv')\n",
    "pred = pd.read_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_results1.csv')\n",
    "\n",
    "# Sort by IMG_NUM for alignment\n",
    "gt = gt.sort_values(by='IMG_NUM').reset_index(drop=True)\n",
    "pred = pred.sort_values(by='IMG_NUM').reset_index(drop=True)\n",
    "\n",
    "assert len(gt) == len(pred), \"Mismatch in number of rows between ground truth and predictions\"\n",
    "\n",
    "# --- Step 2: Calculate Errors ---\n",
    "# Translational Error\n",
    "trans_error = np.linalg.norm(gt[['X', 'Y', 'Z']].values - pred[['X', 'Y', 'Z']].values, axis=1)\n",
    "\n",
    "# Rotational Error (Quaternion difference)\n",
    "def quat_error(q1, q2):\n",
    "    dot = np.abs(np.sum(q1 * q2, axis=1))  # absolute dot product\n",
    "    dot = np.clip(dot, -1.0, 1.0)\n",
    "    return 2 * np.arccos(dot) * 180 / np.pi  # degrees\n",
    "\n",
    "q_gt = gt[['Q1', 'Q2', 'Q3', 'W']].values\n",
    "q_pred = pred[['Q1', 'Q2', 'Q3', 'W']].values\n",
    "rot_error = quat_error(q_gt, q_pred)\n",
    "\n",
    "# Total Error\n",
    "total_error = np.sqrt(trans_error**2 + rot_error**2)\n",
    "\n",
    "# --- Step 3: Apply Threshold ---\n",
    "threshold = 170.0  # set your threshold here\n",
    "y_true = np.ones(len(total_error))  # ground truth: always acceptable (1)\n",
    "y_pred = (total_error <= threshold).astype(int)  # 1 = pass, 0 = fail\n",
    "\n",
    "# --- Step 4: Save Everything to CSV ---\n",
    "df_out = pd.DataFrame({\n",
    "    'IMG_NUM': gt['IMG_NUM'],\n",
    "    'Translational_Error': trans_error,\n",
    "    'Rotational_Error': rot_error,\n",
    "    'Total_Error': total_error,\n",
    "    'Pass_or_Fail': y_pred\n",
    "})\n",
    "df_out.to_csv('C:/Users/rohit/Downloads/archive/synthetic_cubesat/test dataset/test/test_pose_error_with_threshold.csv', index=False)\n",
    "\n",
    "# --- Step 5: Metrics ---\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# --- Step 6: Regression Metrics ---\n",
    "mse = mean_squared_error(np.zeros_like(total_error), total_error)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(np.zeros_like(total_error), total_error)\n",
    "\n",
    "\n",
    "# --- Step 7: Plot Metrics and Save ---\n",
    "# Confusion Matrix\n",
    "\n",
    "\n",
    "# F1 Score Plot\n",
    "plt.figure()\n",
    "plt.bar(['F1 Score'], [f1], color='purple')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('F1 Score')\n",
    "plt.savefig('test_f1_score.png')\n",
    "plt.close()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure()\n",
    "plt.bar(['Accuracy'], [accuracy], color='green')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.savefig('test_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 8: Print Metrics ---\n",
    "print(\"ðŸ“Š Classification Metrics:\")\n",
    "print(f\"âœ… Accuracy       : {accuracy:.4f}\")\n",
    "print(f\"âœ… F1 Score       : {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“ˆ Regression Error Metrics on Total Error:\")\n",
    "print(f\"âœ… MSE            : {mse:.4f}\")\n",
    "print(f\"âœ… RMSE           : {rmse:.4f}\")\n",
    "print(f\"âœ… MAE            : {mae:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
